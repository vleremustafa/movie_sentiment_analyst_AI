{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.285714285714286,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 1.7051409482955933,
      "learning_rate": 1.9864285714285715e-05,
      "loss": 0.6879,
      "step": 20
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 2.3807380199432373,
      "learning_rate": 1.9721428571428573e-05,
      "loss": 0.6884,
      "step": 40
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 1.5125629901885986,
      "learning_rate": 1.957857142857143e-05,
      "loss": 0.688,
      "step": 60
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 2.817020893096924,
      "learning_rate": 1.9435714285714285e-05,
      "loss": 0.6753,
      "step": 80
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 1.4176267385482788,
      "learning_rate": 1.9292857142857143e-05,
      "loss": 0.6726,
      "step": 100
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 1.8768527507781982,
      "learning_rate": 1.915e-05,
      "loss": 0.6816,
      "step": 120
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3724653720855713,
      "learning_rate": 1.900714285714286e-05,
      "loss": 0.6744,
      "step": 140
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 1.6680018901824951,
      "learning_rate": 1.8864285714285714e-05,
      "loss": 0.6722,
      "step": 160
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 2.9486985206604004,
      "learning_rate": 1.8721428571428572e-05,
      "loss": 0.6705,
      "step": 180
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 2.822378396987915,
      "learning_rate": 1.857857142857143e-05,
      "loss": 0.6676,
      "step": 200
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 2.7040653228759766,
      "learning_rate": 1.8435714285714288e-05,
      "loss": 0.6654,
      "step": 220
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 1.2257188558578491,
      "learning_rate": 1.8292857142857143e-05,
      "loss": 0.6604,
      "step": 240
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 1.6104393005371094,
      "learning_rate": 1.815e-05,
      "loss": 0.6465,
      "step": 260
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.412843942642212,
      "learning_rate": 1.800714285714286e-05,
      "loss": 0.6656,
      "step": 280
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 4.702573299407959,
      "learning_rate": 1.7864285714285717e-05,
      "loss": 0.6438,
      "step": 300
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 2.105445384979248,
      "learning_rate": 1.7721428571428575e-05,
      "loss": 0.6472,
      "step": 320
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 3.9421682357788086,
      "learning_rate": 1.757857142857143e-05,
      "loss": 0.6543,
      "step": 340
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 2.0090866088867188,
      "learning_rate": 1.7435714285714287e-05,
      "loss": 0.6427,
      "step": 360
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 1.8468778133392334,
      "learning_rate": 1.7292857142857145e-05,
      "loss": 0.6454,
      "step": 380
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 2.279550313949585,
      "learning_rate": 1.7150000000000004e-05,
      "loss": 0.6401,
      "step": 400
    },
    {
      "epoch": 1.2,
      "grad_norm": 4.290299415588379,
      "learning_rate": 1.7007142857142858e-05,
      "loss": 0.6304,
      "step": 420
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 8.28087043762207,
      "learning_rate": 1.6864285714285716e-05,
      "loss": 0.6128,
      "step": 440
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 3.631063222885132,
      "learning_rate": 1.6721428571428574e-05,
      "loss": 0.6152,
      "step": 460
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 2.0457301139831543,
      "learning_rate": 1.6578571428571432e-05,
      "loss": 0.6211,
      "step": 480
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 2.2678308486938477,
      "learning_rate": 1.6435714285714287e-05,
      "loss": 0.6138,
      "step": 500
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 2.2670063972473145,
      "learning_rate": 1.6292857142857145e-05,
      "loss": 0.6024,
      "step": 520
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 8.270574569702148,
      "learning_rate": 1.6150000000000003e-05,
      "loss": 0.5997,
      "step": 540
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.146521091461182,
      "learning_rate": 1.6007142857142858e-05,
      "loss": 0.6006,
      "step": 560
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 3.880190849304199,
      "learning_rate": 1.5864285714285716e-05,
      "loss": 0.5983,
      "step": 580
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 3.6724839210510254,
      "learning_rate": 1.5721428571428574e-05,
      "loss": 0.6018,
      "step": 600
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 4.664694309234619,
      "learning_rate": 1.5578571428571428e-05,
      "loss": 0.5746,
      "step": 620
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 3.893921136856079,
      "learning_rate": 1.5435714285714286e-05,
      "loss": 0.5947,
      "step": 640
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 4.946050643920898,
      "learning_rate": 1.5292857142857144e-05,
      "loss": 0.5739,
      "step": 660
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 6.577032566070557,
      "learning_rate": 1.515e-05,
      "loss": 0.5654,
      "step": 680
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.305752992630005,
      "learning_rate": 1.5007142857142859e-05,
      "loss": 0.5755,
      "step": 700
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 8.028275489807129,
      "learning_rate": 1.4864285714285715e-05,
      "loss": 0.5632,
      "step": 720
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 6.494334697723389,
      "learning_rate": 1.4721428571428573e-05,
      "loss": 0.5382,
      "step": 740
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 6.802648544311523,
      "learning_rate": 1.4578571428571431e-05,
      "loss": 0.5271,
      "step": 760
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 7.195369720458984,
      "learning_rate": 1.4435714285714286e-05,
      "loss": 0.5358,
      "step": 780
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 3.373047351837158,
      "learning_rate": 1.4292857142857144e-05,
      "loss": 0.5452,
      "step": 800
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 8.426292419433594,
      "learning_rate": 1.4150000000000002e-05,
      "loss": 0.5347,
      "step": 820
    },
    {
      "epoch": 2.4,
      "grad_norm": 11.817118644714355,
      "learning_rate": 1.400714285714286e-05,
      "loss": 0.5699,
      "step": 840
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 9.117034912109375,
      "learning_rate": 1.3864285714285714e-05,
      "loss": 0.547,
      "step": 860
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 9.73974609375,
      "learning_rate": 1.3721428571428572e-05,
      "loss": 0.5284,
      "step": 880
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 23.215375900268555,
      "learning_rate": 1.357857142857143e-05,
      "loss": 0.5114,
      "step": 900
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 2.8057138919830322,
      "learning_rate": 1.3435714285714287e-05,
      "loss": 0.5013,
      "step": 920
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 4.340141296386719,
      "learning_rate": 1.3292857142857143e-05,
      "loss": 0.5463,
      "step": 940
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 8.266080856323242,
      "learning_rate": 1.3150000000000001e-05,
      "loss": 0.512,
      "step": 960
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.35733699798584,
      "learning_rate": 1.3007142857142857e-05,
      "loss": 0.4883,
      "step": 980
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 7.744734764099121,
      "learning_rate": 1.2864285714285716e-05,
      "loss": 0.5001,
      "step": 1000
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 4.543026447296143,
      "learning_rate": 1.2721428571428574e-05,
      "loss": 0.4929,
      "step": 1020
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 2.964695692062378,
      "learning_rate": 1.2578571428571428e-05,
      "loss": 0.5149,
      "step": 1040
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 10.369317054748535,
      "learning_rate": 1.2435714285714286e-05,
      "loss": 0.5128,
      "step": 1060
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 5.110625743865967,
      "learning_rate": 1.2292857142857144e-05,
      "loss": 0.4644,
      "step": 1080
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 10.652710914611816,
      "learning_rate": 1.2150000000000002e-05,
      "loss": 0.4601,
      "step": 1100
    },
    {
      "epoch": 3.2,
      "grad_norm": 9.489992141723633,
      "learning_rate": 1.2007142857142857e-05,
      "loss": 0.4972,
      "step": 1120
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 5.245811939239502,
      "learning_rate": 1.1864285714285715e-05,
      "loss": 0.5097,
      "step": 1140
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 4.013296604156494,
      "learning_rate": 1.1721428571428573e-05,
      "loss": 0.4733,
      "step": 1160
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 3.5308871269226074,
      "learning_rate": 1.1578571428571431e-05,
      "loss": 0.4741,
      "step": 1180
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 14.815144538879395,
      "learning_rate": 1.1435714285714286e-05,
      "loss": 0.467,
      "step": 1200
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 19.14028549194336,
      "learning_rate": 1.1292857142857144e-05,
      "loss": 0.4616,
      "step": 1220
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 8.89828109741211,
      "learning_rate": 1.1150000000000002e-05,
      "loss": 0.4737,
      "step": 1240
    },
    {
      "epoch": 3.6,
      "grad_norm": 7.524413585662842,
      "learning_rate": 1.1007142857142858e-05,
      "loss": 0.4468,
      "step": 1260
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 11.119284629821777,
      "learning_rate": 1.0864285714285716e-05,
      "loss": 0.4673,
      "step": 1280
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 10.153585433959961,
      "learning_rate": 1.0721428571428572e-05,
      "loss": 0.5008,
      "step": 1300
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 12.040078163146973,
      "learning_rate": 1.0578571428571429e-05,
      "loss": 0.4572,
      "step": 1320
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 5.594845294952393,
      "learning_rate": 1.0435714285714287e-05,
      "loss": 0.4825,
      "step": 1340
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 11.299529075622559,
      "learning_rate": 1.0292857142857145e-05,
      "loss": 0.5018,
      "step": 1360
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 8.834773063659668,
      "learning_rate": 1.015e-05,
      "loss": 0.4642,
      "step": 1380
    },
    {
      "epoch": 4.0,
      "grad_norm": 8.273529052734375,
      "learning_rate": 1.0007142857142857e-05,
      "loss": 0.4435,
      "step": 1400
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 10.907920837402344,
      "learning_rate": 9.864285714285715e-06,
      "loss": 0.4555,
      "step": 1420
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 6.469408988952637,
      "learning_rate": 9.721428571428573e-06,
      "loss": 0.4153,
      "step": 1440
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 10.096053123474121,
      "learning_rate": 9.57857142857143e-06,
      "loss": 0.4576,
      "step": 1460
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 5.223258972167969,
      "learning_rate": 9.435714285714286e-06,
      "loss": 0.4442,
      "step": 1480
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 7.044834613800049,
      "learning_rate": 9.292857142857144e-06,
      "loss": 0.4142,
      "step": 1500
    }
  ],
  "logging_steps": 20,
  "max_steps": 2800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7622922240000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
