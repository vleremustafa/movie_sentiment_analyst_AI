{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 2800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 1.7051409482955933,
      "learning_rate": 1.9864285714285715e-05,
      "loss": 0.6879,
      "step": 20
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 2.3807380199432373,
      "learning_rate": 1.9721428571428573e-05,
      "loss": 0.6884,
      "step": 40
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 1.5125629901885986,
      "learning_rate": 1.957857142857143e-05,
      "loss": 0.688,
      "step": 60
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 2.817020893096924,
      "learning_rate": 1.9435714285714285e-05,
      "loss": 0.6753,
      "step": 80
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 1.4176267385482788,
      "learning_rate": 1.9292857142857143e-05,
      "loss": 0.6726,
      "step": 100
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 1.8768527507781982,
      "learning_rate": 1.915e-05,
      "loss": 0.6816,
      "step": 120
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3724653720855713,
      "learning_rate": 1.900714285714286e-05,
      "loss": 0.6744,
      "step": 140
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 1.6680018901824951,
      "learning_rate": 1.8864285714285714e-05,
      "loss": 0.6722,
      "step": 160
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 2.9486985206604004,
      "learning_rate": 1.8721428571428572e-05,
      "loss": 0.6705,
      "step": 180
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 2.822378396987915,
      "learning_rate": 1.857857142857143e-05,
      "loss": 0.6676,
      "step": 200
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 2.7040653228759766,
      "learning_rate": 1.8435714285714288e-05,
      "loss": 0.6654,
      "step": 220
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 1.2257188558578491,
      "learning_rate": 1.8292857142857143e-05,
      "loss": 0.6604,
      "step": 240
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 1.6104393005371094,
      "learning_rate": 1.815e-05,
      "loss": 0.6465,
      "step": 260
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.412843942642212,
      "learning_rate": 1.800714285714286e-05,
      "loss": 0.6656,
      "step": 280
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 4.702573299407959,
      "learning_rate": 1.7864285714285717e-05,
      "loss": 0.6438,
      "step": 300
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 2.105445384979248,
      "learning_rate": 1.7721428571428575e-05,
      "loss": 0.6472,
      "step": 320
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 3.9421682357788086,
      "learning_rate": 1.757857142857143e-05,
      "loss": 0.6543,
      "step": 340
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 2.0090866088867188,
      "learning_rate": 1.7435714285714287e-05,
      "loss": 0.6427,
      "step": 360
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 1.8468778133392334,
      "learning_rate": 1.7292857142857145e-05,
      "loss": 0.6454,
      "step": 380
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 2.279550313949585,
      "learning_rate": 1.7150000000000004e-05,
      "loss": 0.6401,
      "step": 400
    },
    {
      "epoch": 1.2,
      "grad_norm": 4.290299415588379,
      "learning_rate": 1.7007142857142858e-05,
      "loss": 0.6304,
      "step": 420
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 8.28087043762207,
      "learning_rate": 1.6864285714285716e-05,
      "loss": 0.6128,
      "step": 440
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 3.631063222885132,
      "learning_rate": 1.6721428571428574e-05,
      "loss": 0.6152,
      "step": 460
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 2.0457301139831543,
      "learning_rate": 1.6578571428571432e-05,
      "loss": 0.6211,
      "step": 480
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 2.2678308486938477,
      "learning_rate": 1.6435714285714287e-05,
      "loss": 0.6138,
      "step": 500
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 2.2670063972473145,
      "learning_rate": 1.6292857142857145e-05,
      "loss": 0.6024,
      "step": 520
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 8.270574569702148,
      "learning_rate": 1.6150000000000003e-05,
      "loss": 0.5997,
      "step": 540
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.146521091461182,
      "learning_rate": 1.6007142857142858e-05,
      "loss": 0.6006,
      "step": 560
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 3.880190849304199,
      "learning_rate": 1.5864285714285716e-05,
      "loss": 0.5983,
      "step": 580
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 3.6724839210510254,
      "learning_rate": 1.5721428571428574e-05,
      "loss": 0.6018,
      "step": 600
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 4.664694309234619,
      "learning_rate": 1.5578571428571428e-05,
      "loss": 0.5746,
      "step": 620
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 3.893921136856079,
      "learning_rate": 1.5435714285714286e-05,
      "loss": 0.5947,
      "step": 640
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 4.946050643920898,
      "learning_rate": 1.5292857142857144e-05,
      "loss": 0.5739,
      "step": 660
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 6.577032566070557,
      "learning_rate": 1.515e-05,
      "loss": 0.5654,
      "step": 680
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.305752992630005,
      "learning_rate": 1.5007142857142859e-05,
      "loss": 0.5755,
      "step": 700
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 8.028275489807129,
      "learning_rate": 1.4864285714285715e-05,
      "loss": 0.5632,
      "step": 720
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 6.494334697723389,
      "learning_rate": 1.4721428571428573e-05,
      "loss": 0.5382,
      "step": 740
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 6.802648544311523,
      "learning_rate": 1.4578571428571431e-05,
      "loss": 0.5271,
      "step": 760
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 7.195369720458984,
      "learning_rate": 1.4435714285714286e-05,
      "loss": 0.5358,
      "step": 780
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 3.373047351837158,
      "learning_rate": 1.4292857142857144e-05,
      "loss": 0.5452,
      "step": 800
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 8.426292419433594,
      "learning_rate": 1.4150000000000002e-05,
      "loss": 0.5347,
      "step": 820
    },
    {
      "epoch": 2.4,
      "grad_norm": 11.817118644714355,
      "learning_rate": 1.400714285714286e-05,
      "loss": 0.5699,
      "step": 840
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 9.117034912109375,
      "learning_rate": 1.3864285714285714e-05,
      "loss": 0.547,
      "step": 860
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 9.73974609375,
      "learning_rate": 1.3721428571428572e-05,
      "loss": 0.5284,
      "step": 880
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 23.215375900268555,
      "learning_rate": 1.357857142857143e-05,
      "loss": 0.5114,
      "step": 900
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 2.8057138919830322,
      "learning_rate": 1.3435714285714287e-05,
      "loss": 0.5013,
      "step": 920
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 4.340141296386719,
      "learning_rate": 1.3292857142857143e-05,
      "loss": 0.5463,
      "step": 940
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 8.266080856323242,
      "learning_rate": 1.3150000000000001e-05,
      "loss": 0.512,
      "step": 960
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.35733699798584,
      "learning_rate": 1.3007142857142857e-05,
      "loss": 0.4883,
      "step": 980
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 7.744734764099121,
      "learning_rate": 1.2864285714285716e-05,
      "loss": 0.5001,
      "step": 1000
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 4.543026447296143,
      "learning_rate": 1.2721428571428574e-05,
      "loss": 0.4929,
      "step": 1020
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 2.964695692062378,
      "learning_rate": 1.2578571428571428e-05,
      "loss": 0.5149,
      "step": 1040
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 10.369317054748535,
      "learning_rate": 1.2435714285714286e-05,
      "loss": 0.5128,
      "step": 1060
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 5.110625743865967,
      "learning_rate": 1.2292857142857144e-05,
      "loss": 0.4644,
      "step": 1080
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 10.652710914611816,
      "learning_rate": 1.2150000000000002e-05,
      "loss": 0.4601,
      "step": 1100
    },
    {
      "epoch": 3.2,
      "grad_norm": 9.489992141723633,
      "learning_rate": 1.2007142857142857e-05,
      "loss": 0.4972,
      "step": 1120
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 5.245811939239502,
      "learning_rate": 1.1864285714285715e-05,
      "loss": 0.5097,
      "step": 1140
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 4.013296604156494,
      "learning_rate": 1.1721428571428573e-05,
      "loss": 0.4733,
      "step": 1160
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 3.5308871269226074,
      "learning_rate": 1.1578571428571431e-05,
      "loss": 0.4741,
      "step": 1180
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 14.815144538879395,
      "learning_rate": 1.1435714285714286e-05,
      "loss": 0.467,
      "step": 1200
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 19.14028549194336,
      "learning_rate": 1.1292857142857144e-05,
      "loss": 0.4616,
      "step": 1220
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 8.89828109741211,
      "learning_rate": 1.1150000000000002e-05,
      "loss": 0.4737,
      "step": 1240
    },
    {
      "epoch": 3.6,
      "grad_norm": 7.524413585662842,
      "learning_rate": 1.1007142857142858e-05,
      "loss": 0.4468,
      "step": 1260
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 11.119284629821777,
      "learning_rate": 1.0864285714285716e-05,
      "loss": 0.4673,
      "step": 1280
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 10.153585433959961,
      "learning_rate": 1.0721428571428572e-05,
      "loss": 0.5008,
      "step": 1300
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 12.040078163146973,
      "learning_rate": 1.0578571428571429e-05,
      "loss": 0.4572,
      "step": 1320
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 5.594845294952393,
      "learning_rate": 1.0435714285714287e-05,
      "loss": 0.4825,
      "step": 1340
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 11.299529075622559,
      "learning_rate": 1.0292857142857145e-05,
      "loss": 0.5018,
      "step": 1360
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 8.834773063659668,
      "learning_rate": 1.015e-05,
      "loss": 0.4642,
      "step": 1380
    },
    {
      "epoch": 4.0,
      "grad_norm": 8.273529052734375,
      "learning_rate": 1.0007142857142857e-05,
      "loss": 0.4435,
      "step": 1400
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 10.907920837402344,
      "learning_rate": 9.864285714285715e-06,
      "loss": 0.4555,
      "step": 1420
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 6.469408988952637,
      "learning_rate": 9.721428571428573e-06,
      "loss": 0.4153,
      "step": 1440
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 10.096053123474121,
      "learning_rate": 9.57857142857143e-06,
      "loss": 0.4576,
      "step": 1460
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 5.223258972167969,
      "learning_rate": 9.435714285714286e-06,
      "loss": 0.4442,
      "step": 1480
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 7.044834613800049,
      "learning_rate": 9.292857142857144e-06,
      "loss": 0.4142,
      "step": 1500
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 10.344893455505371,
      "learning_rate": 9.15e-06,
      "loss": 0.4251,
      "step": 1520
    },
    {
      "epoch": 4.4,
      "grad_norm": 5.892020225524902,
      "learning_rate": 9.007142857142857e-06,
      "loss": 0.4786,
      "step": 1540
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 9.305368423461914,
      "learning_rate": 8.864285714285715e-06,
      "loss": 0.4728,
      "step": 1560
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 9.268310546875,
      "learning_rate": 8.721428571428571e-06,
      "loss": 0.4488,
      "step": 1580
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 9.795743942260742,
      "learning_rate": 8.57857142857143e-06,
      "loss": 0.4423,
      "step": 1600
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 5.1391921043396,
      "learning_rate": 8.435714285714286e-06,
      "loss": 0.4237,
      "step": 1620
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 8.811368942260742,
      "learning_rate": 8.292857142857144e-06,
      "loss": 0.4553,
      "step": 1640
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 7.759222030639648,
      "learning_rate": 8.15e-06,
      "loss": 0.4611,
      "step": 1660
    },
    {
      "epoch": 4.8,
      "grad_norm": 8.869485855102539,
      "learning_rate": 8.007142857142858e-06,
      "loss": 0.3846,
      "step": 1680
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 8.640226364135742,
      "learning_rate": 7.864285714285716e-06,
      "loss": 0.4336,
      "step": 1700
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 7.21143913269043,
      "learning_rate": 7.721428571428572e-06,
      "loss": 0.4496,
      "step": 1720
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 17.780567169189453,
      "learning_rate": 7.5785714285714295e-06,
      "loss": 0.4605,
      "step": 1740
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 24.763561248779297,
      "learning_rate": 7.435714285714286e-06,
      "loss": 0.4301,
      "step": 1760
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 5.8980393409729,
      "learning_rate": 7.292857142857144e-06,
      "loss": 0.389,
      "step": 1780
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 2.969331979751587,
      "learning_rate": 7.15e-06,
      "loss": 0.467,
      "step": 1800
    },
    {
      "epoch": 5.2,
      "grad_norm": 6.672654151916504,
      "learning_rate": 7.007142857142858e-06,
      "loss": 0.4226,
      "step": 1820
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 20.579830169677734,
      "learning_rate": 6.8642857142857145e-06,
      "loss": 0.434,
      "step": 1840
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 19.602270126342773,
      "learning_rate": 6.721428571428572e-06,
      "loss": 0.4088,
      "step": 1860
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 5.220673561096191,
      "learning_rate": 6.578571428571429e-06,
      "loss": 0.4665,
      "step": 1880
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 5.764538288116455,
      "learning_rate": 6.435714285714286e-06,
      "loss": 0.4324,
      "step": 1900
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 10.564517974853516,
      "learning_rate": 6.292857142857144e-06,
      "loss": 0.4065,
      "step": 1920
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 3.8424530029296875,
      "learning_rate": 6.15e-06,
      "loss": 0.4105,
      "step": 1940
    },
    {
      "epoch": 5.6,
      "grad_norm": 4.904743194580078,
      "learning_rate": 6.0071428571428584e-06,
      "loss": 0.3986,
      "step": 1960
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 24.073991775512695,
      "learning_rate": 5.864285714285715e-06,
      "loss": 0.4728,
      "step": 1980
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 29.005290985107422,
      "learning_rate": 5.721428571428572e-06,
      "loss": 0.433,
      "step": 2000
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 6.000898838043213,
      "learning_rate": 5.578571428571429e-06,
      "loss": 0.4232,
      "step": 2020
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 7.670627117156982,
      "learning_rate": 5.435714285714286e-06,
      "loss": 0.4182,
      "step": 2040
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 11.535006523132324,
      "learning_rate": 5.292857142857143e-06,
      "loss": 0.4363,
      "step": 2060
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 15.265356063842773,
      "learning_rate": 5.150000000000001e-06,
      "loss": 0.4362,
      "step": 2080
    },
    {
      "epoch": 6.0,
      "grad_norm": 6.063713550567627,
      "learning_rate": 5.007142857142857e-06,
      "loss": 0.4108,
      "step": 2100
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 8.408689498901367,
      "learning_rate": 4.864285714285715e-06,
      "loss": 0.4238,
      "step": 2120
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 6.958001613616943,
      "learning_rate": 4.721428571428572e-06,
      "loss": 0.449,
      "step": 2140
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 3.1433160305023193,
      "learning_rate": 4.5785714285714285e-06,
      "loss": 0.4117,
      "step": 2160
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 11.080504417419434,
      "learning_rate": 4.435714285714286e-06,
      "loss": 0.399,
      "step": 2180
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 6.593975067138672,
      "learning_rate": 4.292857142857143e-06,
      "loss": 0.4416,
      "step": 2200
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 22.75250244140625,
      "learning_rate": 4.15e-06,
      "loss": 0.3929,
      "step": 2220
    },
    {
      "epoch": 6.4,
      "grad_norm": 8.26235294342041,
      "learning_rate": 4.007142857142857e-06,
      "loss": 0.3895,
      "step": 2240
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 5.106899261474609,
      "learning_rate": 3.864285714285715e-06,
      "loss": 0.4189,
      "step": 2260
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 27.42829704284668,
      "learning_rate": 3.721428571428572e-06,
      "loss": 0.4475,
      "step": 2280
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 5.459660053253174,
      "learning_rate": 3.5785714285714292e-06,
      "loss": 0.4122,
      "step": 2300
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 5.036322593688965,
      "learning_rate": 3.435714285714286e-06,
      "loss": 0.4143,
      "step": 2320
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 5.431078910827637,
      "learning_rate": 3.292857142857143e-06,
      "loss": 0.3571,
      "step": 2340
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 5.237977027893066,
      "learning_rate": 3.1500000000000003e-06,
      "loss": 0.4384,
      "step": 2360
    },
    {
      "epoch": 6.8,
      "grad_norm": 12.518577575683594,
      "learning_rate": 3.0071428571428575e-06,
      "loss": 0.4091,
      "step": 2380
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 15.833093643188477,
      "learning_rate": 2.8642857142857143e-06,
      "loss": 0.4147,
      "step": 2400
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 16.061601638793945,
      "learning_rate": 2.7214285714285714e-06,
      "loss": 0.3643,
      "step": 2420
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 16.980323791503906,
      "learning_rate": 2.5785714285714286e-06,
      "loss": 0.4145,
      "step": 2440
    },
    {
      "epoch": 7.0285714285714285,
      "grad_norm": 4.37210750579834,
      "learning_rate": 2.435714285714286e-06,
      "loss": 0.4353,
      "step": 2460
    },
    {
      "epoch": 7.085714285714285,
      "grad_norm": 17.409147262573242,
      "learning_rate": 2.292857142857143e-06,
      "loss": 0.4176,
      "step": 2480
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 11.543073654174805,
      "learning_rate": 2.15e-06,
      "loss": 0.4709,
      "step": 2500
    },
    {
      "epoch": 7.2,
      "grad_norm": 6.706894397735596,
      "learning_rate": 2.0071428571428573e-06,
      "loss": 0.4122,
      "step": 2520
    },
    {
      "epoch": 7.257142857142857,
      "grad_norm": 5.668717861175537,
      "learning_rate": 1.8642857142857143e-06,
      "loss": 0.3847,
      "step": 2540
    },
    {
      "epoch": 7.314285714285714,
      "grad_norm": 3.9779775142669678,
      "learning_rate": 1.7214285714285717e-06,
      "loss": 0.4215,
      "step": 2560
    },
    {
      "epoch": 7.371428571428572,
      "grad_norm": 5.806726455688477,
      "learning_rate": 1.5785714285714287e-06,
      "loss": 0.3935,
      "step": 2580
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 14.654583930969238,
      "learning_rate": 1.4357142857142859e-06,
      "loss": 0.3717,
      "step": 2600
    },
    {
      "epoch": 7.485714285714286,
      "grad_norm": 4.2813591957092285,
      "learning_rate": 1.2928571428571428e-06,
      "loss": 0.4056,
      "step": 2620
    },
    {
      "epoch": 7.542857142857143,
      "grad_norm": 9.353553771972656,
      "learning_rate": 1.1500000000000002e-06,
      "loss": 0.4351,
      "step": 2640
    },
    {
      "epoch": 7.6,
      "grad_norm": 15.952855110168457,
      "learning_rate": 1.0071428571428572e-06,
      "loss": 0.3728,
      "step": 2660
    },
    {
      "epoch": 7.6571428571428575,
      "grad_norm": 6.619535446166992,
      "learning_rate": 8.642857142857144e-07,
      "loss": 0.3941,
      "step": 2680
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 4.312608242034912,
      "learning_rate": 7.214285714285715e-07,
      "loss": 0.3897,
      "step": 2700
    },
    {
      "epoch": 7.771428571428571,
      "grad_norm": 6.175921440124512,
      "learning_rate": 5.785714285714286e-07,
      "loss": 0.4598,
      "step": 2720
    },
    {
      "epoch": 7.828571428571428,
      "grad_norm": 9.825455665588379,
      "learning_rate": 4.357142857142858e-07,
      "loss": 0.3692,
      "step": 2740
    },
    {
      "epoch": 7.885714285714286,
      "grad_norm": 27.3432559967041,
      "learning_rate": 2.9285714285714287e-07,
      "loss": 0.4374,
      "step": 2760
    },
    {
      "epoch": 7.942857142857143,
      "grad_norm": 32.76934814453125,
      "learning_rate": 1.5000000000000002e-07,
      "loss": 0.396,
      "step": 2780
    },
    {
      "epoch": 8.0,
      "grad_norm": 14.813090324401855,
      "learning_rate": 7.142857142857144e-09,
      "loss": 0.4067,
      "step": 2800
    }
  ],
  "logging_steps": 20,
  "max_steps": 2800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 14229454848000.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
